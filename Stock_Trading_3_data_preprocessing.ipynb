{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TC_D-kGalP-p",
        "cYxkH48zp2s6",
        "fceb585d",
        "44NKJmaG0gI-",
        "LA2WcgmY8NMk",
        "9ee82290",
        "b4a5d594",
        "da14b478",
        "qKMFox-LtxRL",
        "d76UDaTWrrVR",
        "z03eZ9aaytnQ",
        "mhBROcm5_ssC",
        "GFcVLrlLy2Hp",
        "3cbe1769",
        "9e52d447"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Prepare"
      ],
      "metadata": {
        "id": "TC_D-kGalP-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Google Drive"
      ],
      "metadata": {
        "id": "cYxkH48zp2s6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd9dff2e",
        "outputId": "b0fc0b50-9d04-47f1-dffd-93ad53d35892"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fceb585d"
      },
      "source": [
        "## Load Data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "372ee92a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc7a9cfe-7a90-4115-f179-afa21bd1df91"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the all_stock_data.pkl file into a dictionary\n",
        "all_stocks_dict = pd.read_pickle('/content/drive/MyDrive/Quant Trading/Stock Price/all_stock_data.pkl')\n",
        "\n",
        "# Initialize an empty list to store processed DataFrames\n",
        "all_stocks_list = []\n",
        "\n",
        "# Iterate through the dictionary, add 'ticker' column, and append to the list\n",
        "for ticker, df in all_stocks_dict.items():\n",
        "    df['ticker'] = ticker\n",
        "    all_stocks_list.append(df)\n",
        "\n",
        "# Concatenate all DataFrames in the list into a single DataFrame\n",
        "df_stocks = pd.concat(all_stocks_list, ignore_index=True)\n",
        "\n",
        "df_stocks = df_stocks.drop(columns=['symbol'])\n",
        "\n",
        "print(\"df_stocks loaded.\")\n",
        "print(\"First 5 rows of df_stocks:\")\n",
        "print(df_stocks.head())\n",
        "\n",
        "# Load the stock_price_targets_data.pkl file into a dictionary\n",
        "price_targets_dict = pd.read_pickle('/content/drive/MyDrive/Quant Trading/Stock Price/stock_price_targets_data.pkl')\n",
        "\n",
        "print(\"Stock price targets dictionary loaded.\")\n",
        "print(\"Keys of price_targets_dict:\", price_targets_dict.keys())\n",
        "\n",
        "# Load the stock_volatility_targets_data.pkl file into a dictionary\n",
        "volatility_targets_dict = pd.read_pickle('/content/drive/MyDrive/Quant Trading/Stock Price/stock_volatility_targets_data.pkl')\n",
        "\n",
        "print(\"Stock volatility targets dictionary loaded.\")\n",
        "print(\"Keys of volatility_targets_dict:\", volatility_targets_dict.keys())"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_stocks loaded.\n",
            "First 5 rows of df_stocks:\n",
            "        Date     Close      High       Low                Open    Volume  \\\n",
            "0 1980-03-17  3.145833  3.302083  3.125000               3.125  219600.0   \n",
            "1 1980-03-18  3.031250  3.125000  2.937500               3.125  727200.0   \n",
            "2 1980-03-19  3.041667  3.083333  3.020833             3.03125  295200.0   \n",
            "3 1980-03-20  3.010417  3.062500  3.010417  3.0416669845581055  159600.0   \n",
            "4 1980-03-21  2.916667  3.020833  2.906250  3.0104169845581055  130800.0   \n",
            "\n",
            "      EMA_5    EMA_10    EMA_20    EMA_50  ...  D_5  K_14  D_14      MFI_5  \\\n",
            "0  3.145833  3.145833  3.145833  3.145833  ...  NaN   NaN   NaN   0.000000   \n",
            "1  3.107639  3.125000  3.134920  3.141340  ...  NaN   NaN   NaN   0.000000   \n",
            "2  3.085648  3.109848  3.126039  3.137431  ...  NaN   NaN   NaN  28.990665   \n",
            "3  3.060571  3.091770  3.115027  3.132450  ...  NaN   NaN   NaN  25.085655   \n",
            "4  3.012603  3.059933  3.096136  3.123988  ...  NaN   NaN   NaN  22.651101   \n",
            "\n",
            "      MFI_14     MFI_21  BB_Middle_20  BB_Upper_20  BB_Lower_20  ticker  \n",
            "0   0.000000   0.000000           NaN          NaN          NaN     AMD  \n",
            "1   0.000000   0.000000           NaN          NaN          NaN     AMD  \n",
            "2  28.990665  28.990665           NaN          NaN          NaN     AMD  \n",
            "3  25.085655  25.085655           NaN          NaN          NaN     AMD  \n",
            "4  22.651101  22.651101           NaN          NaN          NaN     AMD  \n",
            "\n",
            "[5 rows x 39 columns]\n",
            "Stock price targets dictionary loaded.\n",
            "Keys of price_targets_dict: dict_keys(['AMD', 'GLD', 'GS', 'INTC', 'JPM', 'META', 'MSFT', 'MU', 'NVDA', 'RXRX', 'TSLA'])\n",
            "Stock volatility targets dictionary loaded.\n",
            "Keys of volatility_targets_dict: dict_keys(['AMD', 'GLD', 'GS', 'INTC', 'JPM', 'META', 'MSFT', 'MU', 'NVDA', 'RXRX', 'TSLA'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialize/ Save/ Load/ Display Processed Data"
      ],
      "metadata": {
        "id": "44NKJmaG0gI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initialize df_stocks_processed"
      ],
      "metadata": {
        "id": "LA2WcgmY8NMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializes df_stocks_processed. It iterates through a dictionary of stock DataFrames, adds a 'ticker' column to each, concatenates them into df_stocks, and then creates df_stocks_processed as a working copy."
      ],
      "metadata": {
        "id": "9Y2O_GSX8UTG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stocks_processed = df_stocks.copy()\n",
        "\n",
        "print(\"df_stocks_processed initialized.\")\n",
        "print(\"First 5 rows of df_stocks_processed:\")\n",
        "print(df_stocks.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oBII_4d00uRH",
        "outputId": "a960a173-862b-47eb-f158-8c8bee932cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_stocks_processed initialized.\n",
            "First 5 rows of df_stocks_processed:\n",
            "        Date     Close      High       Low                Open    Volume  \\\n",
            "0 1980-03-17  3.145833  3.302083  3.125000               3.125  219600.0   \n",
            "1 1980-03-18  3.031250  3.125000  2.937500               3.125  727200.0   \n",
            "2 1980-03-19  3.041667  3.083333  3.020833             3.03125  295200.0   \n",
            "3 1980-03-20  3.010417  3.062500  3.010417  3.0416669845581055  159600.0   \n",
            "4 1980-03-21  2.916667  3.020833  2.906250  3.0104169845581055  130800.0   \n",
            "\n",
            "      EMA_5    EMA_10    EMA_20    EMA_50  ...  D_5  K_14  D_14      MFI_5  \\\n",
            "0  3.145833  3.145833  3.145833  3.145833  ...  NaN   NaN   NaN   0.000000   \n",
            "1  3.107639  3.125000  3.134920  3.141340  ...  NaN   NaN   NaN   0.000000   \n",
            "2  3.085648  3.109848  3.126039  3.137431  ...  NaN   NaN   NaN  28.990665   \n",
            "3  3.060571  3.091770  3.115027  3.132450  ...  NaN   NaN   NaN  25.085655   \n",
            "4  3.012603  3.059933  3.096136  3.123988  ...  NaN   NaN   NaN  22.651101   \n",
            "\n",
            "      MFI_14     MFI_21  BB_Middle_20  BB_Upper_20  BB_Lower_20  ticker  \n",
            "0   0.000000   0.000000           NaN          NaN          NaN     AMD  \n",
            "1   0.000000   0.000000           NaN          NaN          NaN     AMD  \n",
            "2  28.990665  28.990665           NaN          NaN          NaN     AMD  \n",
            "3  25.085655  25.085655           NaN          NaN          NaN     AMD  \n",
            "4  22.651101  22.651101           NaN          NaN          NaN     AMD  \n",
            "\n",
            "[5 rows x 39 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ee82290"
      },
      "source": [
        "### Save df_stocks_processed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "042a9969",
        "outputId": "d05076d8-3165-4bc2-84d5-22520ae6bbb8"
      },
      "source": [
        "import os\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Quant Trading/Preprocessed Data'\n",
        "file_name = 'df_stocks_processed.pkl'\n",
        "full_path = os.path.join(save_path, file_name)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the DataFrame to a pickle file\n",
        "df_stocks_processed.to_pickle(full_path)\n",
        "\n",
        "print(f\"df_stocks_processed successfully saved to: {full_path}\")"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_stocks_processed successfully saved to: /content/drive/MyDrive/Quant Trading/Preprocessed Data/df_stocks_processed.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4a5d594"
      },
      "source": [
        "### Load df_stocks_processed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6612ef2d",
        "outputId": "18d90e6c-e987-486a-8b0b-926093a80bdc"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Quant Trading/Preprocessed Data'\n",
        "file_name = 'df_stocks_processed.pkl'\n",
        "full_path = os.path.join(save_path, file_name)\n",
        "\n",
        "# Load the DataFrame from the pickle file\n",
        "df_stocks_processed = pd.read_pickle(full_path)\n",
        "\n",
        "print(f\"df_stocks_processed successfully loaded from: {full_path}\")\n",
        "print(\"First 5 rows of the loaded DataFrame:\")\n",
        "print(df_stocks_processed.head())\n",
        "\n",
        "print(\"\\nColumns of the loaded DataFrame:\")\n",
        "print(df_stocks_processed.columns.tolist())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_stocks_processed successfully loaded from: /content/drive/MyDrive/Quant Trading/Preprocessed Data/df_stocks_processed.pkl\n",
            "First 5 rows of the loaded DataFrame:\n",
            "        Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "0 1980-03-17       NaN       NaN       NaN       NaN -0.694251 -0.548146   \n",
            "1 1980-03-18       NaN       NaN       NaN       NaN -0.676735 -0.549121   \n",
            "2 1980-03-19 -1.094349 -0.751370 -1.472811      -inf -0.691642 -0.549683   \n",
            "3 1980-03-20 -3.989634 -0.493255 -1.121545 -1.114551 -0.696321 -0.550323   \n",
            "4 1980-03-21  2.031142  1.013651  9.035243 -3.989634 -0.697315 -0.551548   \n",
            "\n",
            "     EMA_10    EMA_20    EMA_50  ...  D_5  K_14  D_14     MFI_5    MFI_14  \\\n",
            "0 -0.548995 -0.550791 -0.556062  ...  NaN   NaN   NaN  0.000000  0.000000   \n",
            "1 -0.549529 -0.551073 -0.556180  ...  NaN   NaN   NaN  0.000000  0.000000   \n",
            "2 -0.549917 -0.551303 -0.556284  ...  NaN   NaN   NaN  0.294317  0.293711   \n",
            "3 -0.550381 -0.551587 -0.556415  ...  NaN   NaN   NaN  0.254673  0.254149   \n",
            "4 -0.551196 -0.552075 -0.556639  ...  NaN   NaN   NaN  0.229957  0.229484   \n",
            "\n",
            "     MFI_21  BB_Middle_20  BB_Upper_20  BB_Lower_20  ticker  \n",
            "0  0.000000           NaN          NaN          NaN     AMD  \n",
            "1  0.000000           NaN          NaN          NaN     AMD  \n",
            "2  0.294589           NaN          NaN          NaN     AMD  \n",
            "3  0.254908           NaN          NaN          NaN     AMD  \n",
            "4  0.230169           NaN          NaN          NaN     AMD  \n",
            "\n",
            "[5 rows x 39 columns]\n",
            "\n",
            "Columns of the loaded DataFrame:\n",
            "['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'SMA_50', 'SMA_100', 'SMA_200', 'RSI_5', 'RSI_14', 'RSI_21', 'MACD', 'Signal_Line', 'MACD_Histogram', 'ATR_5', 'ATR_14', 'ATR_21', 'Volume_SMA_5', 'Volume_SMA_20', 'Volume_SMA_60', 'OBV', 'OBV_Z_Score_20', 'OBV_Z_Score_50', 'K_5', 'D_5', 'K_14', 'D_14', 'MFI_5', 'MFI_14', 'MFI_21', 'BB_Middle_20', 'BB_Upper_20', 'BB_Lower_20', 'ticker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "da14b478"
      },
      "source": [
        "###Interactive Data Comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell allows you to customize the stock, date range, and specific features you want to compare. It will display both the original data (df_stocks) and the processed data (df_stocks_processed) for you to visually verify the data transformation effects."
      ],
      "metadata": {
        "id": "uR8or00i_NVL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "e33ad922",
        "outputId": "2502f801-e8f1-44f9-d117-555ea86c676e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- User configurable parameters ---\n",
        "# You can modify these parameters to select the data to display\n",
        "ticker_selection = 'AMD' # @param {type:\"string\"}\n",
        "start_date_selection = '2020-01-01' # @param {type:\"string\"}\n",
        "days_to_display = 10 # @param {type:\"integer\"}\n",
        "# Modify this list to include any columns you want to compare.\n",
        "# For price columns (Open, Close, High, Low), df_stocks_processed contains daily returns.\n",
        "# For other columns (e.g., Volume, indicators), values in df_stocks and df_stocks_processed may be the same or different due to previous processing.\n",
        "features_to_display = ['MACD'] # @param {type:\"raw\"}\n",
        "\n",
        "# Convert start date to datetime object\n",
        "start_date_dt = pd.to_datetime(start_date_selection)\n",
        "\n",
        "# Define price columns that have been transformed to daily returns in df_stocks_processed\n",
        "price_columns_transformed_to_returns = ['Open', 'Close', 'High', 'Low']\n",
        "\n",
        "# --- Filter and prepare original data (df_stocks) ---\n",
        "df_original_filtered = df_stocks[\n",
        "    (df_stocks['ticker'] == ticker_selection) &\n",
        "    (df_stocks['Date'] >= start_date_dt)\n",
        "].head(days_to_display).copy()\n",
        "\n",
        "# Select 'Date' column and user-specified features from original data, and add '_Original' suffix\n",
        "original_cols_for_display = ['Date']\n",
        "for feature in features_to_display:\n",
        "    if feature in df_original_filtered.columns:\n",
        "        original_cols_for_display.append(feature)\n",
        "df_original_output = df_original_filtered[original_cols_for_display]\n",
        "# Use '_Original_Price' suffix for original price columns, and '_Original' for other features\n",
        "df_original_output.columns = ['Date'] + [f'{col}_Original_Price' if col in price_columns_transformed_to_returns else f'{col}_Original' for col in original_cols_for_display if col != 'Date']\n",
        "\n",
        "# --- Filter and prepare processed data (df_stocks_processed) ---\n",
        "df_processed_filtered = df_stocks_processed[\n",
        "    (df_stocks_processed['ticker'] == ticker_selection) &\n",
        "    (df_stocks_processed['Date'] >= start_date_dt)\n",
        "].head(days_to_display).copy()\n",
        "\n",
        "# Select 'Date' column and user-specified features from processed data, and add '_Processed' suffix\n",
        "processed_cols_for_display = ['Date']\n",
        "for feature in features_to_display:\n",
        "    if feature in df_processed_filtered.columns:\n",
        "        processed_cols_for_display.append(feature)\n",
        "df_processed_output = df_processed_filtered[processed_cols_for_display]\n",
        "# Use '_Daily_Return' suffix for price columns that have been converted to daily returns, and '_Processed' for other features\n",
        "df_processed_output.columns = ['Date'] + [f'{col}_Daily_Return' if col in price_columns_transformed_to_returns else f'{col}_Processed' for col in processed_cols_for_display if col != 'Date']\n",
        "\n",
        "# --- Merge and display for side-by-side comparison ---\n",
        "# Merge the two DataFrames based on the 'Date' column\n",
        "comparison_result_df = pd.merge(df_original_output, df_processed_output, on='Date', how='inner')\n",
        "\n",
        "print(f\"Interactive Comparison - Ticker: {ticker_selection}, Start Date: {start_date_selection}, Days to Display: {days_to_display} days\")\n",
        "display(comparison_result_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive Comparison - Ticker: AMD, Start Date: 2020-01-01, Days to Display: 10 days\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Date  MACD_Original  MACD_Processed\n",
              "0 2020-01-02       2.389860        1.304422\n",
              "1 2020-01-03       2.489015        1.361795\n",
              "2 2020-01-06       2.521584        1.380640\n",
              "3 2020-01-07       2.507197        1.372315\n",
              "4 2020-01-08       2.433849        1.329875\n",
              "5 2020-01-09       2.439586        1.333195\n",
              "6 2020-01-10       2.352462        1.282783\n",
              "7 2020-01-13       2.303662        1.254546\n",
              "8 2020-01-14       2.196098        1.192308\n",
              "9 2020-01-15       2.113920        1.144759"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6fa62a2-454c-419b-8de2-5c861317dbde\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>MACD_Original</th>\n",
              "      <th>MACD_Processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>2.389860</td>\n",
              "      <td>1.304422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-03</td>\n",
              "      <td>2.489015</td>\n",
              "      <td>1.361795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>2.521584</td>\n",
              "      <td>1.380640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-07</td>\n",
              "      <td>2.507197</td>\n",
              "      <td>1.372315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-08</td>\n",
              "      <td>2.433849</td>\n",
              "      <td>1.329875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2020-01-09</td>\n",
              "      <td>2.439586</td>\n",
              "      <td>1.333195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2020-01-10</td>\n",
              "      <td>2.352462</td>\n",
              "      <td>1.282783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>2.303662</td>\n",
              "      <td>1.254546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2020-01-14</td>\n",
              "      <td>2.196098</td>\n",
              "      <td>1.192308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2020-01-15</td>\n",
              "      <td>2.113920</td>\n",
              "      <td>1.144759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6fa62a2-454c-419b-8de2-5c861317dbde')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f6fa62a2-454c-419b-8de2-5c861317dbde button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f6fa62a2-454c-419b-8de2-5c861317dbde');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c71c563a-2315-429e-a86a-17aecbef6df8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c71c563a-2315-429e-a86a-17aecbef6df8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_result_df",
              "summary": "{\n  \"name\": \"comparison_result_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-02 00:00:00\",\n        \"max\": \"2020-01-15 00:00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2020-01-14 00:00:00\",\n          \"2020-01-03 00:00:00\",\n          \"2020-01-09 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MACD_Original\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13563945522802695,\n        \"min\": 2.1139204418705972,\n        \"max\": 2.521584060256451,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.196098118256373,\n          2.4890151088733248,\n          2.439586420789901\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MACD_Processed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0784834043167517,\n        \"min\": 1.144758587024549,\n        \"max\": 1.380640016459809,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.1923080540343762,\n          1.3617950411885844,\n          1.3331947220176152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Display Current Columns' Names"
      ],
      "metadata": {
        "id": "qKMFox-LtxRL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "725060d9",
        "outputId": "3a7b3679-f6b4-4f79-80fb-2ff64e5e7794"
      },
      "source": [
        "print(df_stocks_processed.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'SMA_50', 'SMA_100', 'SMA_200', 'RSI_5', 'RSI_14', 'RSI_21', 'MACD', 'Signal_Line', 'MACD_Histogram', 'ATR_5', 'ATR_14', 'ATR_21', 'Volume_SMA_5', 'Volume_SMA_20', 'Volume_SMA_60', 'OBV', 'OBV_Z_Score_20', 'OBV_Z_Score_50', 'K_5', 'D_5', 'K_14', 'D_14', 'MFI_5', 'MFI_14', 'MFI_21', 'BB_Middle_20', 'BB_Upper_20', 'BB_Lower_20', 'ticker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Scaling"
      ],
      "metadata": {
        "id": "d76UDaTWrrVR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Replace Price with Return Rate"
      ],
      "metadata": {
        "id": "z03eZ9aaytnQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Calculation"
      ],
      "metadata": {
        "id": "mhBROcm5_ssC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa66a514"
      },
      "source": [
        "Converts the 'Date' column to datetime and ensures price columns are numeric. It then calculates the daily percentage returns for 'Open', 'Close', 'High', and 'Low' price columns, grouped by 'ticker', and directly replaces the original price columns with these calculated returns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19790892",
        "outputId": "0aecbd8f-4d67-4c8f-a93a-5e4e2e2040d0"
      },
      "source": [
        "df_stocks_processed['Date'] = pd.to_datetime(df_stocks_processed['Date'])\n",
        "\n",
        "price_columns = ['Open', 'Close', 'High', 'Low']\n",
        "for col in price_columns:\n",
        "    df_stocks_processed[col] = pd.to_numeric(df_stocks_processed[col], errors='coerce')\n",
        "\n",
        "# Calculate daily percentage returns for price columns grouped by 'ticker'\n",
        "# and directly replace the original price columns.\n",
        "for col in price_columns:\n",
        "    # Using fill_method=None to explicitly handle NaN for the first value in each group\n",
        "    # and avoid FutureWarning.\n",
        "    df_stocks_processed[col] = df_stocks_processed.groupby('ticker')[col].pct_change(fill_method=None)\n",
        "\n",
        "print(\"Successfully calculated daily returns for price columns and replaced original columns.\")\n",
        "print(\"First 5 rows of df_stocks_processed with updated price columns (now daily returns):\")\n",
        "print(df_stocks_processed[price_columns + ['Date', 'ticker']].head())\n",
        "print(\"Columns after processing:\", df_stocks_processed.columns.tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully calculated daily returns for price columns and replaced original columns.\n",
            "First 5 rows of df_stocks_processed with updated price columns (now daily returns):\n",
            "       Open     Close      High       Low       Date ticker\n",
            "0       NaN       NaN       NaN       NaN 1980-03-17    AMD\n",
            "1       NaN       NaN       NaN       NaN 1980-03-18    AMD\n",
            "2      -inf -1.094349 -0.751370 -1.472811 1980-03-19    AMD\n",
            "3 -1.114551 -3.989634 -0.493255 -1.121545 1980-03-20    AMD\n",
            "4 -3.989634  2.031142  1.013651  9.035243 1980-03-21    AMD\n",
            "Columns after processing: ['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'SMA_50', 'SMA_100', 'SMA_200', 'RSI_5', 'RSI_14', 'RSI_21', 'MACD', 'Signal_Line', 'MACD_Histogram', 'ATR_5', 'ATR_14', 'ATR_21', 'Volume_SMA_5', 'Volume_SMA_20', 'Volume_SMA_60', 'OBV', 'OBV_Z_Score_20', 'OBV_Z_Score_50', 'K_5', 'D_5', 'K_14', 'D_14', 'MFI_5', 'MFI_14', 'MFI_21', 'BB_Middle_20', 'BB_Upper_20', 'BB_Lower_20', 'ticker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Display and make comparision"
      ],
      "metadata": {
        "id": "GFcVLrlLy2Hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output the adjusted data of a given stock for specific dates for comparison and verification"
      ],
      "metadata": {
        "id": "nAvK0CWEzHkq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3142214a",
        "outputId": "bfd72919-8b31-47ff-f898-a761ab83c9f6"
      },
      "source": [
        "# --- User configurable parameters ---\n",
        "# You can modify these parameters to select the data to display\n",
        "ticker_to_compare = 'AMD' # @param {type:\"string\"}\n",
        "start_date = '2020-01-01' # @param {type:\"string\"}\n",
        "days_to_compare = 10 # @param {type:\"integer\"}\n",
        "\n",
        "# Filter original df_stocks for the chosen ticker and date range\n",
        "df_original_prices = df_stocks[\n",
        "    (df_stocks['ticker'] == ticker_to_compare) &\n",
        "    (df_stocks['Date'] >= start_date)\n",
        "].head(days_to_compare).copy()\n",
        "\n",
        "# Filter processed df_stocks_processed for the chosen ticker and date range\n",
        "df_daily_returns = df_stocks_processed[\n",
        "    (df_stocks_processed['ticker'] == ticker_to_compare) &\n",
        "    (df_stocks_processed['Date'] >= start_date)\n",
        "].head(days_to_compare).copy()\n",
        "\n",
        "# Select and rename relevant columns from original prices for clarity\n",
        "original_cols = ['Date', 'Open', 'Close', 'High', 'Low', 'ticker']\n",
        "df_original_prices = df_original_prices[original_cols]\n",
        "df_original_prices.columns = ['Date', 'Open_Original_Price', 'Close_Original_Price', 'High_Original_Price', 'Low_Original_Price', 'ticker']\n",
        "\n",
        "# Select and rename relevant columns from daily returns for clarity\n",
        "return_cols = ['Date', 'Open', 'Close', 'High', 'Low', 'ticker']\n",
        "df_daily_returns = df_daily_returns[return_cols]\n",
        "df_daily_returns.columns = ['Date', 'Open_Daily_Return', 'Close_Daily_Return', 'High_Daily_Return', 'Low_Daily_Return', 'ticker']\n",
        "\n",
        "# Merge the two DataFrames on 'Date' and 'ticker' for side-by-side comparison\n",
        "comparison_df = pd.merge(df_original_prices, df_daily_returns, on=['Date', 'ticker'], how='inner')\n",
        "\n",
        "print(f\"Comparison for ticker: {ticker_to_compare} starting from {start_date} for {days_to_compare} days:\")\n",
        "display(comparison_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison for ticker: AMD starting from 2020-01-01 for 10 days:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Date Open_Original_Price  Close_Original_Price  High_Original_Price  \\\n",
              "0 2020-01-02   46.86000061035156             49.099998            49.250000   \n",
              "1 2020-01-03  48.029998779296875             48.599998            49.389999   \n",
              "2 2020-01-06   48.02000045776367             48.389999            48.860001   \n",
              "3 2020-01-07  49.349998474121094             48.250000            49.389999   \n",
              "4 2020-01-08  47.849998474121094             47.830002            48.299999   \n",
              "5 2020-01-09  48.939998626708984             48.970001            49.959999   \n",
              "6 2020-01-10    49.2599983215332             48.169998            49.290001   \n",
              "7 2020-01-13   48.65999984741211             48.750000            48.860001   \n",
              "8 2020-01-14   48.63999938964844             48.209999            49.040001   \n",
              "9 2020-01-15   48.22999954223633             48.549999            49.080002   \n",
              "\n",
              "   Low_Original_Price ticker  Open_Daily_Return  Close_Daily_Return  \\\n",
              "0           46.630001    AMD          -2.712615            8.458751   \n",
              "1           47.540001    AMD          -0.371338           -1.144138   \n",
              "2           47.860001    AMD          -1.008337           -0.575681   \n",
              "3           48.040001    AMD        -134.049826           -0.330440   \n",
              "4           47.139999    AMD          -2.097426            2.008705   \n",
              "5           48.389999    AMD          -1.749446           -3.738130   \n",
              "6           48.000000    AMD          -0.712961           -1.685421   \n",
              "7           48.240002    AMD          -2.862817           -1.737040   \n",
              "8           47.910000    AMD          -0.966255           -1.919956   \n",
              "9           48.119999    AMD          19.507952           -1.636681   \n",
              "\n",
              "   High_Daily_Return  Low_Daily_Return  \n",
              "0         -40.569539          5.538909  \n",
              "1          -0.958539         -0.487353  \n",
              "2          -4.774991         -0.655083  \n",
              "3          -2.010847         -0.441259  \n",
              "4          -3.034540         -5.981266  \n",
              "5          -2.557304         -2.415403  \n",
              "6          -1.390203         -1.303940  \n",
              "7          -0.349483         -1.620390  \n",
              "8          -1.422289         -2.368157  \n",
              "9          -0.778589         -1.640741  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eee4e544-d618-4f85-b656-21fb2570c17f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open_Original_Price</th>\n",
              "      <th>Close_Original_Price</th>\n",
              "      <th>High_Original_Price</th>\n",
              "      <th>Low_Original_Price</th>\n",
              "      <th>ticker</th>\n",
              "      <th>Open_Daily_Return</th>\n",
              "      <th>Close_Daily_Return</th>\n",
              "      <th>High_Daily_Return</th>\n",
              "      <th>Low_Daily_Return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>46.86000061035156</td>\n",
              "      <td>49.099998</td>\n",
              "      <td>49.250000</td>\n",
              "      <td>46.630001</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-2.712615</td>\n",
              "      <td>8.458751</td>\n",
              "      <td>-40.569539</td>\n",
              "      <td>5.538909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-03</td>\n",
              "      <td>48.029998779296875</td>\n",
              "      <td>48.599998</td>\n",
              "      <td>49.389999</td>\n",
              "      <td>47.540001</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-0.371338</td>\n",
              "      <td>-1.144138</td>\n",
              "      <td>-0.958539</td>\n",
              "      <td>-0.487353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>48.02000045776367</td>\n",
              "      <td>48.389999</td>\n",
              "      <td>48.860001</td>\n",
              "      <td>47.860001</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-1.008337</td>\n",
              "      <td>-0.575681</td>\n",
              "      <td>-4.774991</td>\n",
              "      <td>-0.655083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-07</td>\n",
              "      <td>49.349998474121094</td>\n",
              "      <td>48.250000</td>\n",
              "      <td>49.389999</td>\n",
              "      <td>48.040001</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-134.049826</td>\n",
              "      <td>-0.330440</td>\n",
              "      <td>-2.010847</td>\n",
              "      <td>-0.441259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-08</td>\n",
              "      <td>47.849998474121094</td>\n",
              "      <td>47.830002</td>\n",
              "      <td>48.299999</td>\n",
              "      <td>47.139999</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-2.097426</td>\n",
              "      <td>2.008705</td>\n",
              "      <td>-3.034540</td>\n",
              "      <td>-5.981266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2020-01-09</td>\n",
              "      <td>48.939998626708984</td>\n",
              "      <td>48.970001</td>\n",
              "      <td>49.959999</td>\n",
              "      <td>48.389999</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-1.749446</td>\n",
              "      <td>-3.738130</td>\n",
              "      <td>-2.557304</td>\n",
              "      <td>-2.415403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2020-01-10</td>\n",
              "      <td>49.2599983215332</td>\n",
              "      <td>48.169998</td>\n",
              "      <td>49.290001</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-0.712961</td>\n",
              "      <td>-1.685421</td>\n",
              "      <td>-1.390203</td>\n",
              "      <td>-1.303940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>48.65999984741211</td>\n",
              "      <td>48.750000</td>\n",
              "      <td>48.860001</td>\n",
              "      <td>48.240002</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-2.862817</td>\n",
              "      <td>-1.737040</td>\n",
              "      <td>-0.349483</td>\n",
              "      <td>-1.620390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2020-01-14</td>\n",
              "      <td>48.63999938964844</td>\n",
              "      <td>48.209999</td>\n",
              "      <td>49.040001</td>\n",
              "      <td>47.910000</td>\n",
              "      <td>AMD</td>\n",
              "      <td>-0.966255</td>\n",
              "      <td>-1.919956</td>\n",
              "      <td>-1.422289</td>\n",
              "      <td>-2.368157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2020-01-15</td>\n",
              "      <td>48.22999954223633</td>\n",
              "      <td>48.549999</td>\n",
              "      <td>49.080002</td>\n",
              "      <td>48.119999</td>\n",
              "      <td>AMD</td>\n",
              "      <td>19.507952</td>\n",
              "      <td>-1.636681</td>\n",
              "      <td>-0.778589</td>\n",
              "      <td>-1.640741</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eee4e544-d618-4f85-b656-21fb2570c17f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eee4e544-d618-4f85-b656-21fb2570c17f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eee4e544-d618-4f85-b656-21fb2570c17f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_c096e488-58d9-478e-ba3e-a338d24e6bca\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c096e488-58d9-478e-ba3e-a338d24e6bca button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('comparison_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "comparison_df",
              "summary": "{\n  \"name\": \"comparison_df\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2020-01-02 00:00:00\",\n        \"max\": \"2020-01-15 00:00:00\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2020-01-14 00:00:00\",\n          \"2020-01-03 00:00:00\",\n          \"2020-01-09 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open_Original_Price\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"48.63999938964844\",\n          \"48.029998779296875\",\n          \"48.939998626708984\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close_Original_Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3900367798611429,\n        \"min\": 47.83000183105469,\n        \"max\": 49.09999847412109,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          48.209999084472656,\n          48.59999847412109,\n          48.970001220703125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High_Original_Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.43562960186981387,\n        \"min\": 48.29999923706055,\n        \"max\": 49.959999084472656,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          49.38999938964844,\n          49.290000915527344,\n          49.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low_Original_Price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5403505502075743,\n        \"min\": 46.630001068115234,\n        \"max\": 48.38999938964844,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          47.90999984741211,\n          47.540000915527344,\n          48.38999938964844\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"AMD\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open_Daily_Return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 43.15609954437181,\n        \"min\": -134.04982570971814,\n        \"max\": 19.507952447040395,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -0.9662547943377647\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close_Daily_Return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.383005492949859,\n        \"min\": -3.738130494334251,\n        \"max\": 8.45875144876642,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -1.9199561801340284\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High_Daily_Return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.290297763666022,\n        \"min\": -40.569539046963705,\n        \"max\": -0.34948286065728607,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -1.4222890650731386\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low_Daily_Return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8448464101543984,\n        \"min\": -5.981265580584324,\n        \"max\": 5.538908944219635,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          -2.368157179453312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-Q32cqgV0uQv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cbe1769"
      },
      "source": [
        "##Apply Standardization to Other Columns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e52d447"
      },
      "source": [
        "### Apply Z-score Standardization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Z-score standardization to columns in `df_stocks_processed` that are typically unbounded or require a distribution with a mean of 0 and standard deviation of 1. This includes 'Volume', various EMA/SMA indicators, MACD-related metrics, ATR, Volume SMAs, and Bollinger Bands. Columns that are already named 'Z_Score' will be excluded to avoid re-scaling."
      ],
      "metadata": {
        "id": "KVHYUKdC-Enk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fed66a26",
        "outputId": "9c12e64f-e83c-4091-9c7a-ee5a0e778b50"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Define columns to apply Z-score standardization to\n",
        "columns_to_zscore = [\n",
        "    'Volume', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'SMA_50', 'SMA_100', 'SMA_200',\n",
        "    'MACD', 'Signal_Line', 'MACD_Histogram',\n",
        "    'ATR_5', 'ATR_14', 'ATR_21',\n",
        "    'Volume_SMA_5', 'Volume_SMA_20', 'Volume_SMA_60', 'OBV',\n",
        "    'BB_Middle_20', 'BB_Upper_20', 'BB_Lower_20'\n",
        "]\n",
        "\n",
        "print(\"Columns selected for Z-score standardization:\")\n",
        "print(columns_to_zscore)\n",
        "\n",
        "for col in columns_to_zscore:\n",
        "    # Initialize a new StandardScaler for each column\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Apply Z-score standardization grouped by 'ticker'\n",
        "    # Ensure to handle potential NaN values by dropping them before scaling and re-indexing\n",
        "    # Or, fill NaNs if appropriate for the data and context (here, we'll try to scale existing numbers)\n",
        "    df_stocks_processed[col] = df_stocks_processed.groupby('ticker')[col].transform(\n",
        "        lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten()\n",
        "    )\n",
        "\n",
        "print(\"Z-score standardization successfully applied to specified columns.\")\n",
        "print(\"First 5 rows of df_stocks_processed with Z-score standardized columns:\")\n",
        "print(df_stocks_processed[columns_to_zscore + ['ticker']].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns selected for Z-score standardization:\n",
            "['Volume', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'SMA_50', 'SMA_100', 'SMA_200', 'MACD', 'Signal_Line', 'MACD_Histogram', 'ATR_5', 'ATR_14', 'ATR_21', 'Volume_SMA_5', 'Volume_SMA_20', 'Volume_SMA_60', 'OBV', 'BB_Middle_20', 'BB_Upper_20', 'BB_Lower_20']\n",
            "Z-score standardization successfully applied to specified columns.\n",
            "First 5 rows of df_stocks_processed with Z-score standardized columns:\n",
            "     Volume     EMA_5    EMA_10    EMA_20    EMA_50  SMA_50  SMA_100  SMA_200  \\\n",
            "0 -0.694251 -0.548146 -0.548995 -0.550791 -0.556062     NaN      NaN      NaN   \n",
            "1 -0.676735 -0.549121 -0.549529 -0.551073 -0.556180     NaN      NaN      NaN   \n",
            "2 -0.691642 -0.549683 -0.549917 -0.551303 -0.556284     NaN      NaN      NaN   \n",
            "3 -0.696321 -0.550323 -0.550381 -0.551587 -0.556415     NaN      NaN      NaN   \n",
            "4 -0.697315 -0.551548 -0.551196 -0.552075 -0.556639     NaN      NaN      NaN   \n",
            "\n",
            "       MACD  Signal_Line  ...    ATR_14    ATR_21  Volume_SMA_5  \\\n",
            "0 -0.078393    -0.083684  ... -0.517447 -0.524096           NaN   \n",
            "1 -0.083682    -0.084813  ... -0.515177 -0.522522           NaN   \n",
            "2 -0.087285    -0.086485  ... -0.523802 -0.528436           NaN   \n",
            "3 -0.091449    -0.088711  ... -0.532033 -0.534336           NaN   \n",
            "4 -0.098889    -0.092080  ... -0.534627 -0.536553     -0.736642   \n",
            "\n",
            "   Volume_SMA_20  Volume_SMA_60       OBV  BB_Middle_20  BB_Upper_20  \\\n",
            "0            NaN            NaN -0.522226           NaN          NaN   \n",
            "1            NaN            NaN -0.522616           NaN          NaN   \n",
            "2            NaN            NaN -0.522458           NaN          NaN   \n",
            "3            NaN            NaN -0.522544           NaN          NaN   \n",
            "4            NaN            NaN -0.522614           NaN          NaN   \n",
            "\n",
            "   BB_Lower_20  ticker  \n",
            "0          NaN     AMD  \n",
            "1          NaN     AMD  \n",
            "2          NaN     AMD  \n",
            "3          NaN     AMD  \n",
            "4          NaN     AMD  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Min-Max Scaling"
      ],
      "metadata": {
        "id": "WbxXEfWR-vUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RSI, K, D, and MFI are oscillators with naturally bounded ranges (typically 0-100). Min-Max scaling is suitable for them because it preserves their inherent bounded nature and interpretability (e.g., maintaining the concept of overbought/oversold levels). It linearly transforms them to a new fixed range (like 0-1) without distorting their relative positions, which is beneficial for many machine learning models that expect inputs within a specific range."
      ],
      "metadata": {
        "id": "jIsoJNxz_fQ9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb9ee888",
        "outputId": "dd3b6a36-cd62-4b95-dad2-4374b1481bcd"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define columns to apply Min-Max scaling to\n",
        "columns_to_minmax = [\n",
        "    'RSI_5', 'RSI_14', 'RSI_21',\n",
        "    'K_5', 'D_5', 'K_14', 'D_14',\n",
        "    'MFI_5', 'MFI_14', 'MFI_21'\n",
        "]\n",
        "\n",
        "for col in columns_to_minmax:\n",
        "    # Initialize a new MinMaxScaler for each column\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Apply Min-Max scaling grouped by 'ticker'\n",
        "    df_stocks_processed[col] = df_stocks_processed.groupby('ticker')[col].transform(\n",
        "        lambda x: scaler.fit_transform(x.values.reshape(-1, 1)).flatten()\n",
        "    )\n",
        "\n",
        "print(\"Min-Max scaling successfully applied to specified columns.\")\n",
        "print(\"First 5 rows of df_stocks_processed with Min-Max scaled columns:\")\n",
        "print(df_stocks_processed[columns_to_minmax + ['ticker']].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min-Max scaling successfully applied to specified columns.\n",
            "First 5 rows of df_stocks_processed with Min-Max scaled columns:\n",
            "      RSI_5    RSI_14    RSI_21       K_5  D_5  K_14  D_14     MFI_5  \\\n",
            "0       NaN       NaN       NaN       NaN  NaN   NaN   NaN  0.000000   \n",
            "1  0.000000  0.000000  0.000000       NaN  NaN   NaN   NaN  0.000000   \n",
            "2  0.104131  0.098830  0.102472       NaN  NaN   NaN   NaN  0.294317   \n",
            "3  0.075313  0.076726  0.080403       NaN  NaN   NaN   NaN  0.254673   \n",
            "4  0.036957  0.044541  0.047905  0.026317  NaN   NaN   NaN  0.229957   \n",
            "\n",
            "     MFI_14    MFI_21 ticker  \n",
            "0  0.000000  0.000000    AMD  \n",
            "1  0.000000  0.000000    AMD  \n",
            "2  0.293711  0.294589    AMD  \n",
            "3  0.254149  0.254908    AMD  \n",
            "4  0.229484  0.230169    AMD  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature-Target Integration"
      ],
      "metadata": {
        "id": "3YaeUXHCDIQU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "435156e3"
      },
      "source": [
        "##Initialization/ Save/ Load"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initialize df_features_and_targets"
      ],
      "metadata": {
        "id": "cHDXBtISKAUI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize `df_features_and_targets` by copying `df_stocks_processed` to prepare for integrating features and targets."
      ],
      "metadata": {
        "id": "kyDwf9yQI390"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "149f4857",
        "outputId": "e9f6df71-412d-4891-83f5-77fb9356ccb1"
      },
      "source": [
        "df_features_and_targets = df_stocks_processed.copy()\n",
        "\n",
        "print(\"df_features_and_targets initialized as a copy of df_stocks_processed.\")\n",
        "print(\"First 5 rows of df_features_and_targets:\")\n",
        "print(df_features_and_targets.head())\n",
        "\n",
        "print(\"\\nColumns of df_features_and_targets:\")\n",
        "print(df_features_and_targets.columns.tolist())"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_features_and_targets initialized as a copy of df_stocks_processed.\n",
            "First 5 rows of df_features_and_targets:\n",
            "        Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "0 1980-03-17       NaN       NaN       NaN       NaN -0.694251 -0.548146   \n",
            "1 1980-03-18       NaN       NaN       NaN       NaN -0.676735 -0.549121   \n",
            "2 1980-03-19 -1.094349 -0.751370 -1.472811      -inf -0.691642 -0.549683   \n",
            "3 1980-03-20 -3.989634 -0.493255 -1.121545 -1.114551 -0.696321 -0.550323   \n",
            "4 1980-03-21  2.031142  1.013651  9.035243 -3.989634 -0.697315 -0.551548   \n",
            "\n",
            "     EMA_10    EMA_20    EMA_50  ...  D_5  K_14  D_14     MFI_5    MFI_14  \\\n",
            "0 -0.548995 -0.550791 -0.556062  ...  NaN   NaN   NaN  0.000000  0.000000   \n",
            "1 -0.549529 -0.551073 -0.556180  ...  NaN   NaN   NaN  0.000000  0.000000   \n",
            "2 -0.549917 -0.551303 -0.556284  ...  NaN   NaN   NaN  0.294317  0.293711   \n",
            "3 -0.550381 -0.551587 -0.556415  ...  NaN   NaN   NaN  0.254673  0.254149   \n",
            "4 -0.551196 -0.552075 -0.556639  ...  NaN   NaN   NaN  0.229957  0.229484   \n",
            "\n",
            "     MFI_21  BB_Middle_20  BB_Upper_20  BB_Lower_20  ticker  \n",
            "0  0.000000           NaN          NaN          NaN     AMD  \n",
            "1  0.000000           NaN          NaN          NaN     AMD  \n",
            "2  0.294589           NaN          NaN          NaN     AMD  \n",
            "3  0.254908           NaN          NaN          NaN     AMD  \n",
            "4  0.230169           NaN          NaN          NaN     AMD  \n",
            "\n",
            "[5 rows x 39 columns]\n",
            "\n",
            "Columns of df_features_and_targets:\n",
            "['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'SMA_50', 'SMA_100', 'SMA_200', 'RSI_5', 'RSI_14', 'RSI_21', 'MACD', 'Signal_Line', 'MACD_Histogram', 'ATR_5', 'ATR_14', 'ATR_21', 'Volume_SMA_5', 'Volume_SMA_20', 'Volume_SMA_60', 'OBV', 'OBV_Z_Score_20', 'OBV_Z_Score_50', 'K_5', 'D_5', 'K_14', 'D_14', 'MFI_5', 'MFI_14', 'MFI_21', 'BB_Middle_20', 'BB_Upper_20', 'BB_Lower_20', 'ticker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Save df_features_and_targets"
      ],
      "metadata": {
        "id": "b1nlwfqOKptQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_1",
        "outputId": "8735aa10-b6c6-42d8-b3a5-3eb7a8161d1d"
      },
      "source": [
        "import os\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Quant Trading/Preprocessed Data'\n",
        "file_name = 'df_features_and_targets.pkl'\n",
        "full_path = os.path.join(save_path, file_name)\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Save the DataFrame to a pickle file\n",
        "df_features_and_targets.to_pickle(full_path)\n",
        "\n",
        "print(f\"df_features_and_targets successfully saved to: {full_path}\")"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_features_and_targets successfully saved to: /content/drive/MyDrive/Quant Trading/Preprocessed Data/df_features_and_targets.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load df_features_and_targets"
      ],
      "metadata": {
        "id": "CwsTyzhMKr4e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "new_cell_3",
        "outputId": "cee2fdcc-6c8c-4a5a-ec96-e65cf4b5a5f0"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Quant Trading/Preprocessed Data'\n",
        "file_name = 'df_features_and_targets.pkl'\n",
        "full_path = os.path.join(save_path, file_name)\n",
        "\n",
        "# Load the DataFrame from the pickle file\n",
        "df_features_and_targets = pd.read_pickle(full_path)\n",
        "\n",
        "print(f\"df_features_and_targets successfully loaded from: {full_path}\")\n",
        "print(\"First 5 rows of the loaded DataFrame:\")\n",
        "print(df_features_and_targets.head())\n",
        "\n",
        "print(\"\\nColumns of the loaded DataFrame:\")\n",
        "print(df_features_and_targets.columns.tolist())"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_features_and_targets successfully loaded from: /content/drive/MyDrive/Quant Trading/Preprocessed Data/df_features_and_targets.pkl\n",
            "First 5 rows of the loaded DataFrame:\n",
            "        Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "0 1980-03-17       NaN       NaN       NaN       NaN -0.694251 -0.548146   \n",
            "1 1980-03-18       NaN       NaN       NaN       NaN -0.676735 -0.549121   \n",
            "2 1980-03-19 -1.094349 -0.751370 -1.472811      -inf -0.691642 -0.549683   \n",
            "3 1980-03-20 -3.989634 -0.493255 -1.121545 -1.114551 -0.696321 -0.550323   \n",
            "4 1980-03-21  2.031142  1.013651  9.035243 -3.989634 -0.697315 -0.551548   \n",
            "\n",
            "     EMA_10    EMA_20    EMA_50  ...  D_5  K_14  D_14     MFI_5    MFI_14  \\\n",
            "0 -0.548995 -0.550791 -0.556062  ...  NaN   NaN   NaN  0.000000  0.000000   \n",
            "1 -0.549529 -0.551073 -0.556180  ...  NaN   NaN   NaN  0.000000  0.000000   \n",
            "2 -0.549917 -0.551303 -0.556284  ...  NaN   NaN   NaN  0.294317  0.293711   \n",
            "3 -0.550381 -0.551587 -0.556415  ...  NaN   NaN   NaN  0.254673  0.254149   \n",
            "4 -0.551196 -0.552075 -0.556639  ...  NaN   NaN   NaN  0.229957  0.229484   \n",
            "\n",
            "     MFI_21  BB_Middle_20  BB_Upper_20  BB_Lower_20  ticker  \n",
            "0  0.000000           NaN          NaN          NaN     AMD  \n",
            "1  0.000000           NaN          NaN          NaN     AMD  \n",
            "2  0.294589           NaN          NaN          NaN     AMD  \n",
            "3  0.254908           NaN          NaN          NaN     AMD  \n",
            "4  0.230169           NaN          NaN          NaN     AMD  \n",
            "\n",
            "[5 rows x 39 columns]\n",
            "\n",
            "Columns of the loaded DataFrame:\n",
            "['Date', 'Close', 'High', 'Low', 'Open', 'Volume', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'SMA_50', 'SMA_100', 'SMA_200', 'RSI_5', 'RSI_14', 'RSI_21', 'MACD', 'Signal_Line', 'MACD_Histogram', 'ATR_5', 'ATR_14', 'ATR_21', 'Volume_SMA_5', 'Volume_SMA_20', 'Volume_SMA_60', 'OBV', 'OBV_Z_Score_20', 'OBV_Z_Score_50', 'K_5', 'D_5', 'K_14', 'D_14', 'MFI_5', 'MFI_14', 'MFI_21', 'BB_Middle_20', 'BB_Upper_20', 'BB_Lower_20', 'ticker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display Number of Columns and rows"
      ],
      "metadata": {
        "id": "v72gf1NVYqgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of columns in df_features_and_targets: {len(df_features_and_targets.columns)}\")\n",
        "print(f\"Number of rows in df_features_and_targets: {len(df_features_and_targets)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwprK1pzYvG0",
        "outputId": "efb5f2b9-674f-48ac-fbd5-8ce716469d4b"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns in df_features_and_targets: 143\n",
            "Number of rows in df_features_and_targets: 79982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Add New Columns to df_features_and_targets"
      ],
      "metadata": {
        "id": "6Qs21Q_uLVoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###For Price Target Set"
      ],
      "metadata": {
        "id": "yaUZuQNNT7yt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Show Keys of Price Target Set"
      ],
      "metadata": {
        "id": "zFyd4O-YJbjS"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca36b1b1",
        "outputId": "57d1af66-fa20-4033-b259-40c71fdf9459"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"Inspecting the unique keys at each level of price_targets_dict:\")\n",
        "\n",
        "unique_tickers = set()\n",
        "unique_target_types = set()\n",
        "unique_time_periods = set()\n",
        "unique_percentage_thresholds = set()\n",
        "\n",
        "for ticker, targets_by_type in price_targets_dict.items():\n",
        "    unique_tickers.add(ticker)\n",
        "\n",
        "    if isinstance(targets_by_type, dict):\n",
        "        for target_type, targets_by_period in targets_by_type.items():\n",
        "            unique_target_types.add(target_type)\n",
        "\n",
        "            if isinstance(targets_by_period, dict):\n",
        "                for time_period, targets_by_threshold in targets_by_period.items():\n",
        "                    unique_time_periods.add(time_period)\n",
        "\n",
        "                    if isinstance(targets_by_threshold, dict):\n",
        "                        for threshold_key in targets_by_threshold.keys():\n",
        "                            unique_percentage_thresholds.add(threshold_key)\n",
        "\n",
        "print(f\"\\nLevel 1 (Tickers): {sorted(list(unique_tickers))}\")\n",
        "print(f\"Level 2 (Target Types): {sorted(list(unique_target_types))}\")\n",
        "print(f\"Level 3 (Time Periods): {sorted(list(unique_time_periods))}\")\n",
        "print(f\"Level 4 (Percentage Thresholds): {sorted(list(unique_percentage_thresholds))}\")\n",
        "\n",
        "print(\"\\nUnique keys inspection complete.\")"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting the unique keys at each level of price_targets_dict:\n",
            "\n",
            "Level 1 (Tickers): ['AMD', 'GLD', 'GS', 'INTC', 'JPM', 'META', 'MSFT', 'MU', 'NVDA', 'RXRX', 'TSLA']\n",
            "Level 2 (Target Types): ['close_down', 'close_up', 'high_reach', 'low_reach']\n",
            "Level 3 (Time Periods): ['100d', '1d', '20d', '250d', '5d']\n",
            "Level 4 (Percentage Thresholds): ['10pct', '20pct', '2pct', '50pct', '5pct']\n",
            "\n",
            "Unique keys inspection complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Create and Fulfill New Columns"
      ],
      "metadata": {
        "id": "n9BlOjDYSat5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aa50c9e"
      },
      "source": [
        "Iterate through `price_targets_dict`, generate sorted combinations of target types, time periods, and percentage thresholds to create descriptive column names, and merge the corresponding target values as new columns into `df_features_and_targets`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62c3ddb4",
        "outputId": "f09fe824-20d5-45e8-d65b-db047f0251a8"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Helper functions to sort keys numerically\n",
        "def sort_time_periods(periods):\n",
        "    # Sorts '1d', '5d', '20d', '100d', '250d' numerically\n",
        "    return sorted(periods, key=lambda x: int(x[:-1]))\n",
        "\n",
        "def sort_percentage_thresholds(thresholds):\n",
        "    # Sorts '2pct', '5pct', '10pct', '20pct', '50pct' numerically\n",
        "    return sorted(thresholds, key=lambda x: int(x[:-3]))\n",
        "\n",
        "# Get and sort the unique keys from the previously inspected structure\n",
        "sorted_target_types = sorted(list(unique_target_types))\n",
        "sorted_time_periods = sort_time_periods(list(unique_time_periods))\n",
        "sorted_percentage_thresholds = sort_percentage_thresholds(list(unique_percentage_thresholds))\n",
        "\n",
        "# Initialize an empty list to store flattened target DataFrames for each ticker\n",
        "all_price_targets_flattened = []\n",
        "\n",
        "# Iterate through each ticker in price_targets_dict in sorted order\n",
        "for ticker in sorted(list(price_targets_dict.keys())):\n",
        "    # Dictionary to hold all Series for the current ticker, keyed by the new column name\n",
        "    current_ticker_series_collection = {}\n",
        "\n",
        "    # Iterate through sorted combinations of target types, time periods, and percentage thresholds\n",
        "    for target_type in sorted_target_types:\n",
        "        for time_period in sorted_time_periods:\n",
        "            for percentage_threshold in sorted_percentage_thresholds:\n",
        "                # Construct the new descriptive column name\n",
        "                col_name = f'price_target_{target_type}_{time_period}_{percentage_threshold}'\n",
        "\n",
        "                # Access the corresponding pandas Series\n",
        "                # Use .get() with a default value (e.g., empty Series) to handle missing combinations gracefully if any\n",
        "                series_data = price_targets_dict.get(ticker, {})\n",
        "                series_data = series_data.get(target_type, {})\n",
        "                series_data = series_data.get(time_period, {})\n",
        "                series_data = series_data.get(percentage_threshold)\n",
        "\n",
        "                if series_data is not None and not series_data.empty:\n",
        "                    current_ticker_series_collection[col_name] = series_data\n",
        "\n",
        "    # If there are any series collected for the current ticker, combine them into a DataFrame\n",
        "    if current_ticker_series_collection:\n",
        "        df_ticker_targets_combined = pd.DataFrame(current_ticker_series_collection)\n",
        "        df_ticker_targets_combined['ticker'] = ticker\n",
        "        df_ticker_targets_combined.reset_index(inplace=True) # 'index' will become 'Date'\n",
        "        df_ticker_targets_combined.rename(columns={'index': 'Date'}, inplace=True)\n",
        "        all_price_targets_flattened.append(df_ticker_targets_combined)\n",
        "\n",
        "# Concatenate all ticker-specific flattened DataFrames into one large DataFrame\n",
        "df_flattened_price_targets = pd.DataFrame()\n",
        "if all_price_targets_flattened:\n",
        "    df_flattened_price_targets = pd.concat(all_price_targets_flattened, ignore_index=True)\n",
        "    df_flattened_price_targets['Date'] = pd.to_datetime(df_flattened_price_targets['Date'])\n",
        "\n",
        "    print(\"\\nFlattened Price Targets DataFrame head:\")\n",
        "    print(df_flattened_price_targets.head())\n",
        "    print(\"\\nFlattened Price Targets DataFrame columns (first 5 and last 5):\")\n",
        "    print(df_flattened_price_targets.columns.tolist()[:5] + df_flattened_price_targets.columns.tolist()[-5:])\n",
        "else:\n",
        "    print(\"No price targets found to flatten.\")\n",
        "\n",
        "# Merge the flattened price targets into df_features_and_targets\n",
        "df_features_and_targets = pd.merge(\n",
        "    df_features_and_targets,\n",
        "    df_flattened_price_targets,\n",
        "    on=['Date', 'ticker'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(\"\\nAfter merging price targets, df_features_and_targets head:\")\n",
        "print(df_features_and_targets.head())\n",
        "print(\"\\nAfter merging price targets, df_features_and_targets tail:\")\n",
        "print(df_features_and_targets.tail())\n",
        "print(\"\\nAfter merging price targets, df_features_and_targets columns (first 5 and last 5):\")\n",
        "print(df_features_and_targets.columns.tolist()[:5] + df_features_and_targets.columns.tolist()[-5:])"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Flattened Price Targets DataFrame head:\n",
            "        Date  price_target_close_down_1d_2pct  \\\n",
            "0 1980-03-17                              1.0   \n",
            "1 1980-03-18                              0.0   \n",
            "2 1980-03-19                              0.0   \n",
            "3 1980-03-20                              1.0   \n",
            "4 1980-03-21                              1.0   \n",
            "\n",
            "   price_target_close_down_1d_5pct  price_target_close_down_1d_10pct  \\\n",
            "0                              0.0                               0.0   \n",
            "1                              0.0                               0.0   \n",
            "2                              0.0                               0.0   \n",
            "3                              0.0                               0.0   \n",
            "4                              1.0                               0.0   \n",
            "\n",
            "   price_target_close_down_1d_20pct  price_target_close_down_1d_50pct  \\\n",
            "0                               0.0                               0.0   \n",
            "1                               0.0                               0.0   \n",
            "2                               0.0                               0.0   \n",
            "3                               0.0                               0.0   \n",
            "4                               0.0                               0.0   \n",
            "\n",
            "   price_target_close_down_5d_2pct  price_target_close_down_5d_5pct  \\\n",
            "0                              1.0                              1.0   \n",
            "1                              1.0                              1.0   \n",
            "2                              1.0                              1.0   \n",
            "3                              1.0                              1.0   \n",
            "4                              1.0                              1.0   \n",
            "\n",
            "   price_target_close_down_5d_10pct  price_target_close_down_5d_20pct  ...  \\\n",
            "0                               1.0                               0.0  ...   \n",
            "1                               1.0                               0.0  ...   \n",
            "2                               1.0                               0.0  ...   \n",
            "3                               1.0                               1.0  ...   \n",
            "4                               1.0                               0.0  ...   \n",
            "\n",
            "   price_target_low_reach_100d_5pct  price_target_low_reach_100d_10pct  \\\n",
            "0                               1.0                                1.0   \n",
            "1                               1.0                                1.0   \n",
            "2                               1.0                                1.0   \n",
            "3                               1.0                                1.0   \n",
            "4                               1.0                                1.0   \n",
            "\n",
            "   price_target_low_reach_100d_20pct  price_target_low_reach_100d_50pct  \\\n",
            "0                                1.0                                0.0   \n",
            "1                                1.0                                0.0   \n",
            "2                                1.0                                0.0   \n",
            "3                                1.0                                0.0   \n",
            "4                                1.0                                0.0   \n",
            "\n",
            "   price_target_low_reach_250d_2pct  price_target_low_reach_250d_5pct  \\\n",
            "0                               1.0                               1.0   \n",
            "1                               1.0                               1.0   \n",
            "2                               1.0                               1.0   \n",
            "3                               1.0                               1.0   \n",
            "4                               1.0                               1.0   \n",
            "\n",
            "   price_target_low_reach_250d_10pct  price_target_low_reach_250d_20pct  \\\n",
            "0                                1.0                                1.0   \n",
            "1                                1.0                                1.0   \n",
            "2                                1.0                                1.0   \n",
            "3                                1.0                                1.0   \n",
            "4                                1.0                                1.0   \n",
            "\n",
            "   price_target_low_reach_250d_50pct  ticker  \n",
            "0                                0.0     AMD  \n",
            "1                                0.0     AMD  \n",
            "2                                0.0     AMD  \n",
            "3                                0.0     AMD  \n",
            "4                                0.0     AMD  \n",
            "\n",
            "[5 rows x 102 columns]\n",
            "\n",
            "Flattened Price Targets DataFrame columns (first 5 and last 5):\n",
            "['Date', 'price_target_close_down_1d_2pct', 'price_target_close_down_1d_5pct', 'price_target_close_down_1d_10pct', 'price_target_close_down_1d_20pct', 'price_target_low_reach_250d_5pct', 'price_target_low_reach_250d_10pct', 'price_target_low_reach_250d_20pct', 'price_target_low_reach_250d_50pct', 'ticker']\n",
            "\n",
            "After merging price targets, df_features_and_targets head:\n",
            "        Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "0 1980-03-17       NaN       NaN       NaN       NaN -0.694251 -0.548146   \n",
            "1 1980-03-18       NaN       NaN       NaN       NaN -0.676735 -0.549121   \n",
            "2 1980-03-19 -1.094349 -0.751370 -1.472811      -inf -0.691642 -0.549683   \n",
            "3 1980-03-20 -3.989634 -0.493255 -1.121545 -1.114551 -0.696321 -0.550323   \n",
            "4 1980-03-21  2.031142  1.013651  9.035243 -3.989634 -0.697315 -0.551548   \n",
            "\n",
            "     EMA_10    EMA_20    EMA_50  ...  price_target_low_reach_100d_2pct  \\\n",
            "0 -0.548995 -0.550791 -0.556062  ...                               1.0   \n",
            "1 -0.549529 -0.551073 -0.556180  ...                               1.0   \n",
            "2 -0.549917 -0.551303 -0.556284  ...                               1.0   \n",
            "3 -0.550381 -0.551587 -0.556415  ...                               1.0   \n",
            "4 -0.551196 -0.552075 -0.556639  ...                               1.0   \n",
            "\n",
            "   price_target_low_reach_100d_5pct  price_target_low_reach_100d_10pct  \\\n",
            "0                               1.0                                1.0   \n",
            "1                               1.0                                1.0   \n",
            "2                               1.0                                1.0   \n",
            "3                               1.0                                1.0   \n",
            "4                               1.0                                1.0   \n",
            "\n",
            "   price_target_low_reach_100d_20pct  price_target_low_reach_100d_50pct  \\\n",
            "0                                1.0                                0.0   \n",
            "1                                1.0                                0.0   \n",
            "2                                1.0                                0.0   \n",
            "3                                1.0                                0.0   \n",
            "4                                1.0                                0.0   \n",
            "\n",
            "   price_target_low_reach_250d_2pct  price_target_low_reach_250d_5pct  \\\n",
            "0                               1.0                               1.0   \n",
            "1                               1.0                               1.0   \n",
            "2                               1.0                               1.0   \n",
            "3                               1.0                               1.0   \n",
            "4                               1.0                               1.0   \n",
            "\n",
            "   price_target_low_reach_250d_10pct  price_target_low_reach_250d_20pct  \\\n",
            "0                                1.0                                1.0   \n",
            "1                                1.0                                1.0   \n",
            "2                                1.0                                1.0   \n",
            "3                                1.0                                1.0   \n",
            "4                                1.0                                1.0   \n",
            "\n",
            "   price_target_low_reach_250d_50pct  \n",
            "0                                0.0  \n",
            "1                                0.0  \n",
            "2                                0.0  \n",
            "3                                0.0  \n",
            "4                                0.0  \n",
            "\n",
            "[5 rows x 139 columns]\n",
            "\n",
            "After merging price targets, df_features_and_targets tail:\n",
            "            Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "82760 2026-02-06 -2.614536 -1.602063 -1.903626 -1.173947 -0.448159  2.428435   \n",
            "82761 2026-02-09 -0.568341 -0.478008 -0.090520  1.325499 -0.556696  2.443776   \n",
            "82762 2026-02-10  0.251618 -0.118723 -0.006023 -0.116173 -0.424669  2.474603   \n",
            "82763 2026-02-11 -0.619363  0.495369 -0.695217  0.185674 -0.520354  2.503144   \n",
            "82764        NaT       NaN       NaN       NaN       NaN       NaN  2.503144   \n",
            "\n",
            "         EMA_10    EMA_20    EMA_50  ...  price_target_low_reach_100d_2pct  \\\n",
            "82760  2.492967  2.585900  2.714428  ...                               NaN   \n",
            "82761  2.491452  2.578300  2.708870  ...                               NaN   \n",
            "82762  2.501486  2.577369  2.706030  ...                               NaN   \n",
            "82763  2.514067  2.578833  2.704270  ...                               NaN   \n",
            "82764  2.514067  2.578833  2.704270  ...                               NaN   \n",
            "\n",
            "       price_target_low_reach_100d_5pct  price_target_low_reach_100d_10pct  \\\n",
            "82760                               NaN                                NaN   \n",
            "82761                               NaN                                NaN   \n",
            "82762                               NaN                                NaN   \n",
            "82763                               NaN                                NaN   \n",
            "82764                               NaN                                NaN   \n",
            "\n",
            "       price_target_low_reach_100d_20pct  price_target_low_reach_100d_50pct  \\\n",
            "82760                                NaN                                NaN   \n",
            "82761                                NaN                                NaN   \n",
            "82762                                NaN                                NaN   \n",
            "82763                                NaN                                NaN   \n",
            "82764                                NaN                                NaN   \n",
            "\n",
            "       price_target_low_reach_250d_2pct  price_target_low_reach_250d_5pct  \\\n",
            "82760                               NaN                               NaN   \n",
            "82761                               NaN                               NaN   \n",
            "82762                               NaN                               NaN   \n",
            "82763                               NaN                               NaN   \n",
            "82764                               NaN                               NaN   \n",
            "\n",
            "       price_target_low_reach_250d_10pct  price_target_low_reach_250d_20pct  \\\n",
            "82760                                NaN                                NaN   \n",
            "82761                                NaN                                NaN   \n",
            "82762                                NaN                                NaN   \n",
            "82763                                NaN                                NaN   \n",
            "82764                                NaN                                NaN   \n",
            "\n",
            "       price_target_low_reach_250d_50pct  \n",
            "82760                                NaN  \n",
            "82761                                NaN  \n",
            "82762                                NaN  \n",
            "82763                                NaN  \n",
            "82764                                NaN  \n",
            "\n",
            "[5 rows x 139 columns]\n",
            "\n",
            "After merging price targets, df_features_and_targets columns (first 5 and last 5):\n",
            "['Date', 'Close', 'High', 'Low', 'Open', 'price_target_low_reach_250d_2pct', 'price_target_low_reach_250d_5pct', 'price_target_low_reach_250d_10pct', 'price_target_low_reach_250d_20pct', 'price_target_low_reach_250d_50pct']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###For Volatility Target Set"
      ],
      "metadata": {
        "id": "bbBDLX6NULCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Show Keys of Volatility Target Set"
      ],
      "metadata": {
        "id": "eQvn6FNcWPnk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43acac17",
        "outputId": "95eb9e70-12d7-4be3-f7f4-833cbdf328ca"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"Inspecting the unique keys at each level of volatility_targets_dict:\")\n",
        "\n",
        "unique_tickers_vol = set()\n",
        "unique_time_periods_vol = set()\n",
        "\n",
        "for ticker, targets_by_period in volatility_targets_dict.items():\n",
        "    unique_tickers_vol.add(ticker)\n",
        "\n",
        "    if isinstance(targets_by_period, dict):\n",
        "        for time_period, series_data in targets_by_period.items():\n",
        "            unique_time_periods_vol.add(time_period)\n",
        "\n",
        "print(f\"\\nLevel 1 (Tickers): {sorted(list(unique_tickers_vol))}\")\n",
        "print(f\"Level 2 (Time Periods): {sorted(list(unique_time_periods_vol))}\")\n",
        "\n",
        "print(\"\\nUnique keys inspection complete for volatility targets.\")"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inspecting the unique keys at each level of volatility_targets_dict:\n",
            "\n",
            "Level 1 (Tickers): ['AMD', 'GLD', 'GS', 'INTC', 'JPM', 'META', 'MSFT', 'MU', 'NVDA', 'RXRX', 'TSLA']\n",
            "Level 2 (Time Periods): ['100d', '20d', '250d', '5d']\n",
            "\n",
            "Unique keys inspection complete for volatility targets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Create and Fulfil New Columns"
      ],
      "metadata": {
        "id": "59WGHvIIWT00"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c46f083f",
        "outputId": "6d34aa3e-c319-4e8c-fa9b-19db03a2d880"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Get and sort the unique time periods for volatility targets\n",
        "sorted_volatility_time_periods = sort_time_periods(list(unique_time_periods_vol))\n",
        "\n",
        "print(f\"Sorted Volatility Time Periods: {sorted_volatility_time_periods}\")\n",
        "\n",
        "# Initialize an empty list to store flattened volatility target DataFrames for each ticker\n",
        "all_volatility_targets_flattened = []\n",
        "\n",
        "# Iterate through each ticker in volatility_targets_dict in sorted order\n",
        "for ticker in sorted(list(volatility_targets_dict.keys())):\n",
        "    # Dictionary to hold all Series for the current ticker, keyed by the new column name\n",
        "    current_ticker_series_collection = {}\n",
        "\n",
        "    # Iterate through sorted time periods for volatility targets\n",
        "    for time_period in sorted_volatility_time_periods:\n",
        "        # Construct the new descriptive column name\n",
        "        col_name = f'volatility_target_{time_period}'\n",
        "\n",
        "        # Access the corresponding pandas Series\n",
        "        series_data = volatility_targets_dict.get(ticker, {})\n",
        "        series_data = series_data.get(time_period)\n",
        "\n",
        "        if series_data is not None and not series_data.empty:\n",
        "            current_ticker_series_collection[col_name] = series_data\n",
        "\n",
        "    # If there are any series collected for the current ticker, combine them into a DataFrame\n",
        "    if current_ticker_series_collection:\n",
        "        df_ticker_vol_targets_combined = pd.DataFrame(current_ticker_series_collection)\n",
        "        df_ticker_vol_targets_combined['ticker'] = ticker\n",
        "        df_ticker_vol_targets_combined.reset_index(inplace=True)  # 'index' will become 'Date'\n",
        "        df_ticker_vol_targets_combined.rename(columns={'index': 'Date'}, inplace=True)\n",
        "        all_volatility_targets_flattened.append(df_ticker_vol_targets_combined)\n",
        "\n",
        "# Concatenate all ticker-specific flattened DataFrames into one large DataFrame\n",
        "df_flattened_volatility_targets = pd.DataFrame()\n",
        "if all_volatility_targets_flattened:\n",
        "    df_flattened_volatility_targets = pd.concat(all_volatility_targets_flattened, ignore_index=True)\n",
        "    df_flattened_volatility_targets['Date'] = pd.to_datetime(df_flattened_volatility_targets['Date'])\n",
        "\n",
        "    print(\"\\nFlattened Volatility Targets DataFrame head:\")\n",
        "    print(df_flattened_volatility_targets.head())\n",
        "    print(\"\\nFlattened Volatility Targets DataFrame columns (first 5 and last 5):\")\n",
        "    print(df_flattened_volatility_targets.columns.tolist()[:5] + df_flattened_volatility_targets.columns.tolist()[-5:])\n",
        "else:\n",
        "    print(\"No volatility targets found to flatten.\")\n",
        "\n",
        "# Merge the flattened volatility targets into df_features_and_targets\n",
        "df_features_and_targets = pd.merge(\n",
        "    df_features_and_targets,\n",
        "    df_flattened_volatility_targets,\n",
        "    on=['Date', 'ticker'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(\"\\nAfter merging volatility targets, df_features_and_targets head:\")\n",
        "print(df_features_and_targets.head())\n",
        "print(\"\\nAfter merging volatility targets, df_features_and_targets tail:\")\n",
        "print(df_features_and_targets.tail())\n",
        "print(\"\\nAfter merging volatility targets, df_features_and_targets columns (first 5 and last 5):\")\n",
        "print(df_features_and_targets.columns.tolist()[:5] + df_features_and_targets.columns.tolist()[-5:])"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Volatility Time Periods: ['5d', '20d', '100d', '250d']\n",
            "\n",
            "Flattened Volatility Targets DataFrame head:\n",
            "        Date  volatility_target_5d  volatility_target_20d  \\\n",
            "0 1980-03-17                   NaN                    NaN   \n",
            "1 1980-03-18                   NaN                    NaN   \n",
            "2 1980-03-19              2.866207               2.866207   \n",
            "3 1980-03-20              2.061265               2.061265   \n",
            "4 1980-03-21              1.884814               1.884814   \n",
            "\n",
            "   volatility_target_100d  volatility_target_250d ticker  \n",
            "0                     NaN                     NaN    AMD  \n",
            "1                     NaN                     NaN    AMD  \n",
            "2                2.866207                2.866207    AMD  \n",
            "3                2.061265                2.061265    AMD  \n",
            "4                1.884814                1.884814    AMD  \n",
            "\n",
            "Flattened Volatility Targets DataFrame columns (first 5 and last 5):\n",
            "['Date', 'volatility_target_5d', 'volatility_target_20d', 'volatility_target_100d', 'volatility_target_250d', 'volatility_target_5d', 'volatility_target_20d', 'volatility_target_100d', 'volatility_target_250d', 'ticker']\n",
            "\n",
            "After merging volatility targets, df_features_and_targets head:\n",
            "        Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "0 1980-03-17       NaN       NaN       NaN       NaN -0.694251 -0.548146   \n",
            "1 1980-03-18       NaN       NaN       NaN       NaN -0.676735 -0.549121   \n",
            "2 1980-03-19 -1.094349 -0.751370 -1.472811      -inf -0.691642 -0.549683   \n",
            "3 1980-03-20 -3.989634 -0.493255 -1.121545 -1.114551 -0.696321 -0.550323   \n",
            "4 1980-03-21  2.031142  1.013651  9.035243 -3.989634 -0.697315 -0.551548   \n",
            "\n",
            "     EMA_10    EMA_20    EMA_50  ...  price_target_low_reach_100d_50pct  \\\n",
            "0 -0.548995 -0.550791 -0.556062  ...                                0.0   \n",
            "1 -0.549529 -0.551073 -0.556180  ...                                0.0   \n",
            "2 -0.549917 -0.551303 -0.556284  ...                                0.0   \n",
            "3 -0.550381 -0.551587 -0.556415  ...                                0.0   \n",
            "4 -0.551196 -0.552075 -0.556639  ...                                0.0   \n",
            "\n",
            "   price_target_low_reach_250d_2pct  price_target_low_reach_250d_5pct  \\\n",
            "0                               1.0                               1.0   \n",
            "1                               1.0                               1.0   \n",
            "2                               1.0                               1.0   \n",
            "3                               1.0                               1.0   \n",
            "4                               1.0                               1.0   \n",
            "\n",
            "   price_target_low_reach_250d_10pct  price_target_low_reach_250d_20pct  \\\n",
            "0                                1.0                                1.0   \n",
            "1                                1.0                                1.0   \n",
            "2                                1.0                                1.0   \n",
            "3                                1.0                                1.0   \n",
            "4                                1.0                                1.0   \n",
            "\n",
            "   price_target_low_reach_250d_50pct  volatility_target_5d  \\\n",
            "0                                0.0                   NaN   \n",
            "1                                0.0                   NaN   \n",
            "2                                0.0              2.866207   \n",
            "3                                0.0              2.061265   \n",
            "4                                0.0              1.884814   \n",
            "\n",
            "   volatility_target_20d  volatility_target_100d  volatility_target_250d  \n",
            "0                    NaN                     NaN                     NaN  \n",
            "1                    NaN                     NaN                     NaN  \n",
            "2               2.866207                2.866207                2.866207  \n",
            "3               2.061265                2.061265                2.061265  \n",
            "4               1.884814                1.884814                1.884814  \n",
            "\n",
            "[5 rows x 143 columns]\n",
            "\n",
            "After merging volatility targets, df_features_and_targets tail:\n",
            "            Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "82760 2026-02-06 -2.614536 -1.602063 -1.903626 -1.173947 -0.448159  2.428435   \n",
            "82761 2026-02-09 -0.568341 -0.478008 -0.090520  1.325499 -0.556696  2.443776   \n",
            "82762 2026-02-10  0.251618 -0.118723 -0.006023 -0.116173 -0.424669  2.474603   \n",
            "82763 2026-02-11 -0.619363  0.495369 -0.695217  0.185674 -0.520354  2.503144   \n",
            "82764        NaT       NaN       NaN       NaN       NaN       NaN  2.503144   \n",
            "\n",
            "         EMA_10    EMA_20    EMA_50  ...  price_target_low_reach_100d_50pct  \\\n",
            "82760  2.492967  2.585900  2.714428  ...                                NaN   \n",
            "82761  2.491452  2.578300  2.708870  ...                                NaN   \n",
            "82762  2.501486  2.577369  2.706030  ...                                NaN   \n",
            "82763  2.514067  2.578833  2.704270  ...                                NaN   \n",
            "82764  2.514067  2.578833  2.704270  ...                                NaN   \n",
            "\n",
            "       price_target_low_reach_250d_2pct  price_target_low_reach_250d_5pct  \\\n",
            "82760                               NaN                               NaN   \n",
            "82761                               NaN                               NaN   \n",
            "82762                               NaN                               NaN   \n",
            "82763                               NaN                               NaN   \n",
            "82764                               NaN                               NaN   \n",
            "\n",
            "       price_target_low_reach_250d_10pct  price_target_low_reach_250d_20pct  \\\n",
            "82760                                NaN                                NaN   \n",
            "82761                                NaN                                NaN   \n",
            "82762                                NaN                                NaN   \n",
            "82763                                NaN                                NaN   \n",
            "82764                                NaN                                NaN   \n",
            "\n",
            "       price_target_low_reach_250d_50pct  volatility_target_5d  \\\n",
            "82760                                NaN              2.799349   \n",
            "82761                                NaN              2.893958   \n",
            "82762                                NaN              3.046231   \n",
            "82763                                NaN              2.073905   \n",
            "82764                                NaN              1.144504   \n",
            "\n",
            "       volatility_target_20d  volatility_target_100d  volatility_target_250d  \n",
            "82760               2.505978                2.826941                3.912456  \n",
            "82761               2.479705                2.817065                3.908526  \n",
            "82762               2.514626                2.821574                3.887497  \n",
            "82763               2.524043                2.814169                3.884938  \n",
            "82764               2.564585                2.819972                3.876903  \n",
            "\n",
            "[5 rows x 143 columns]\n",
            "\n",
            "After merging volatility targets, df_features_and_targets columns (first 5 and last 5):\n",
            "['Date', 'Close', 'High', 'Low', 'Open', 'price_target_low_reach_250d_50pct', 'volatility_target_5d', 'volatility_target_20d', 'volatility_target_100d', 'volatility_target_250d']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clear NaN Rows"
      ],
      "metadata": {
        "id": "AaPwNTozWe-k"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cf1de91",
        "outputId": "39c36808-d148-4dd3-cd0b-b828efb61a9c"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Identify all target columns (those starting with 'price_target_' or 'volatility_target_')\n",
        "target_columns = [col for col in df_features_and_targets.columns if col.startswith('price_target_') or col.startswith('volatility_target_')]\n",
        "\n",
        "print(f\"Total number of target columns identified: {len(target_columns)}\")\n",
        "\n",
        "# Before dropping NaNs, let's inspect NaN counts in target columns\n",
        "initial_rows = len(df_features_and_targets)\n",
        "print(f\"\\nInitial number of rows in df_features_and_targets: {initial_rows}\")\n",
        "\n",
        "nan_counts_in_targets = df_features_and_targets[target_columns].isnull().sum()\n",
        "columns_with_nan_in_targets = nan_counts_in_targets[nan_counts_in_targets > 0]\n",
        "\n",
        "if not columns_with_nan_in_targets.empty:\n",
        "    print(\"\\nNumber of NaN values per target column (only showing columns with NaNs):\")\n",
        "    print(columns_with_nan_in_targets)\n",
        "    print(f\"\\nTotal NaN values across all target columns: {columns_with_nan_in_targets.sum()}\")\n",
        "else:\n",
        "    print(\"\\nNo NaN values found in any target column before dropping.\")\n",
        "\n",
        "# Drop rows where any of the identified target columns have NaN values\n",
        "df_features_and_targets_cleaned = df_features_and_targets.dropna(subset=target_columns)\n",
        "\n",
        "# After dropping NaNs\n",
        "final_rows = len(df_features_and_targets_cleaned)\n",
        "print(f\"\\nNumber of rows after dropping NaNs in target columns: {final_rows}\")\n",
        "print(f\"Number of rows dropped: {initial_rows - final_rows}\")\n",
        "\n",
        "# Update df_features_and_targets to the cleaned version\n",
        "df_features_and_targets = df_features_and_targets_cleaned.copy()\n",
        "\n",
        "print(\"\\nFirst 5 rows of df_features_and_targets after fulfilling (dropping NaNs) targets:\")\n",
        "print(df_features_and_targets.head())\n",
        "print(\"\\nLast 5 rows of df_features_and_targets after fulfilling (dropping NaNs) targets:\")\n",
        "print(df_features_and_targets.tail())\n",
        "\n",
        "print(\"\\nSummary of NaN values in target columns after cleaning (should be 0 if rows dropped successfully):\")\n",
        "print(df_features_and_targets[target_columns].isnull().sum().sum()) # Should be 0"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of target columns identified: 104\n",
            "\n",
            "Initial number of rows in df_features_and_targets: 82765\n",
            "\n",
            "Number of NaN values per target column (only showing columns with NaNs):\n",
            "price_target_close_down_1d_2pct        22\n",
            "price_target_close_down_1d_5pct        22\n",
            "price_target_close_down_1d_10pct       22\n",
            "price_target_close_down_1d_20pct       22\n",
            "price_target_close_down_1d_50pct       22\n",
            "                                     ... \n",
            "price_target_low_reach_250d_50pct    2739\n",
            "volatility_target_5d                   22\n",
            "volatility_target_20d                  22\n",
            "volatility_target_100d                 22\n",
            "volatility_target_250d                 22\n",
            "Length: 104, dtype: int64\n",
            "\n",
            "Total NaN values across all target columns: 83028\n",
            "\n",
            "Number of rows after dropping NaNs in target columns: 79982\n",
            "Number of rows dropped: 2783\n",
            "\n",
            "First 5 rows of df_features_and_targets after fulfilling (dropping NaNs) targets:\n",
            "        Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "2 1980-03-19 -1.094349 -0.751370 -1.472811      -inf -0.691642 -0.549683   \n",
            "3 1980-03-20 -3.989634 -0.493255 -1.121545 -1.114551 -0.696321 -0.550323   \n",
            "4 1980-03-21  2.031142  1.013651  9.035243 -3.989634 -0.697315 -0.551548   \n",
            "5 1980-03-24  1.752381  1.534448  1.693179  2.031142 -0.686756 -0.554492   \n",
            "6 1980-03-25 -0.726563  0.657156 -0.660684  1.752381 -0.679551 -0.556986   \n",
            "\n",
            "     EMA_10    EMA_20    EMA_50  ...  price_target_low_reach_100d_50pct  \\\n",
            "2 -0.549917 -0.551303 -0.556284  ...                                0.0   \n",
            "3 -0.550381 -0.551587 -0.556415  ...                                0.0   \n",
            "4 -0.551196 -0.552075 -0.556639  ...                                0.0   \n",
            "5 -0.553029 -0.553131 -0.557113  ...                                0.0   \n",
            "6 -0.554819 -0.554241 -0.557633  ...                                0.0   \n",
            "\n",
            "   price_target_low_reach_250d_2pct  price_target_low_reach_250d_5pct  \\\n",
            "2                               1.0                               1.0   \n",
            "3                               1.0                               1.0   \n",
            "4                               1.0                               1.0   \n",
            "5                               1.0                               1.0   \n",
            "6                               1.0                               1.0   \n",
            "\n",
            "   price_target_low_reach_250d_10pct  price_target_low_reach_250d_20pct  \\\n",
            "2                                1.0                                1.0   \n",
            "3                                1.0                                1.0   \n",
            "4                                1.0                                1.0   \n",
            "5                                1.0                                0.0   \n",
            "6                                1.0                                0.0   \n",
            "\n",
            "   price_target_low_reach_250d_50pct  volatility_target_5d  \\\n",
            "2                                0.0              2.866207   \n",
            "3                                0.0              2.061265   \n",
            "4                                0.0              1.884814   \n",
            "5                                0.0              3.558396   \n",
            "6                                0.0              3.570612   \n",
            "\n",
            "   volatility_target_20d  volatility_target_100d  volatility_target_250d  \n",
            "2               2.866207                2.866207                2.866207  \n",
            "3               2.061265                2.061265                2.061265  \n",
            "4               1.884814                1.884814                1.884814  \n",
            "5               3.558396                3.558396                3.558396  \n",
            "6               3.205453                3.205453                3.205453  \n",
            "\n",
            "[5 rows x 143 columns]\n",
            "\n",
            "Last 5 rows of df_features_and_targets after fulfilling (dropping NaNs) targets:\n",
            "            Date     Close      High       Low      Open    Volume     EMA_5  \\\n",
            "82509 2025-02-06 -0.715602  1.348964  1.136808 -3.929846 -0.246246  2.214061   \n",
            "82510 2025-02-07  2.332627 -1.410176 -0.762221 -0.796254 -0.347194  2.155433   \n",
            "82511 2025-02-10 -0.112407 -4.419113  2.488547  3.960310 -0.251589  2.087916   \n",
            "82512 2025-02-11  1.104708 -0.216467  1.657442 -0.226141  0.291953  1.984864   \n",
            "82513 2025-02-12 -1.384708 -0.768693 -1.170570  0.569398  0.117601  1.937077   \n",
            "\n",
            "         EMA_10    EMA_20    EMA_50  ...  price_target_low_reach_100d_50pct  \\\n",
            "82509  2.279684  2.352521  2.312796  ...                                0.0   \n",
            "82510  2.237365  2.325174  2.305338  ...                                0.0   \n",
            "82511  2.187181  2.292224  2.294721  ...                                0.0   \n",
            "82512  2.114360  2.245661  2.277477  ...                                0.0   \n",
            "82513  2.066224  2.209569  2.263448  ...                                0.0   \n",
            "\n",
            "       price_target_low_reach_250d_2pct  price_target_low_reach_250d_5pct  \\\n",
            "82509                               1.0                               1.0   \n",
            "82510                               1.0                               1.0   \n",
            "82511                               1.0                               1.0   \n",
            "82512                               1.0                               1.0   \n",
            "82513                               1.0                               1.0   \n",
            "\n",
            "       price_target_low_reach_250d_10pct  price_target_low_reach_250d_20pct  \\\n",
            "82509                                1.0                                1.0   \n",
            "82510                                1.0                                1.0   \n",
            "82511                                1.0                                1.0   \n",
            "82512                                1.0                                1.0   \n",
            "82513                                1.0                                1.0   \n",
            "\n",
            "       price_target_low_reach_250d_50pct  volatility_target_5d  \\\n",
            "82509                                0.0              3.143099   \n",
            "82510                                0.0              2.917436   \n",
            "82511                                0.0              2.465227   \n",
            "82512                                0.0              1.976944   \n",
            "82513                                0.0              3.307030   \n",
            "\n",
            "       volatility_target_20d  volatility_target_100d  volatility_target_250d  \n",
            "82509               2.915705                4.264977                3.955177  \n",
            "82510               2.999068                4.283067                3.961883  \n",
            "82511               3.053370                4.292891                3.965694  \n",
            "82512               3.255288                4.349321                3.984110  \n",
            "82513               3.338550                4.353577                3.983495  \n",
            "\n",
            "[5 rows x 143 columns]\n",
            "\n",
            "Summary of NaN values in target columns after cleaning (should be 0 if rows dropped successfully):\n",
            "0\n"
          ]
        }
      ]
    }
  ]
}